janice_formula1_data_golden:
  BOT_ID: "Janice"
  PROCESS_NAME: "janice_formula1_data"
  PROCESS_INSTRUCTIONS: |
    1. Search the Snowflake database for tables or views that contain Formula 1 data.
    2. Locate a table or view with DRIVER information.
    3. Query the identified table or view to find the driver with the most wins.
    4. Post the result to the channel #C075LL9KPM3.
  PROCESS_DETAILS: "Search Formula 1 Data"
  TIMESTAMP: "2000-01-01T00:00:00.000Z"

janice_warehouse_sizing_recommendation_golden:
  BOT_ID: "Janice"
  PROCESS_NAME: "janice_assisted_user_creation"
  PROCESS_INSTRUCTIONS: |
    1. Retrieve query history data and calculate average queuing time per hour for each warehouse.
    2. Identify warehouses with average queuing time per hour exceeding 60,000 microseconds.
    3. Display the top 3 warehouses with the highest total queuing times for reference.
    4. Analyze the query history to compute the average swapping to disk per query.
    5. Identify warehouses with an average swapping to disk per query exceeding 100MB (104,857,600 bytes).
    6. Display the top 3 warehouses with the highest average swapping to disk per query for a spot check, regardless of the threshold.
    7. Send an email summary of the analysis to matt@genesiscomputing.ai every Friday at 9 am ET, including recommendations for which warehouses should be made multi-cluster or resized, DataCube URLs for both queuing and swapping spot checks, and the process ID for reference.
    8. Add a description at the top of the email to explain the purpose of the email for future recipients.
  PROCESS_DETAILS: "Analyze Warehouse Queuing and Swapping"
  TIMESTAMP: "2000-01-01T00:00:00.000Z"

janice_monitor_unused_tables_golden:
  BOT_ID: "Janice"
  PROCESS_NAME: "janice_assisted_user_creation"
  PROCESS_INSTRUCTIONS: |
    # Monitor Unused Tables - New Process Description

    ## Overview
    This process identifies and notifies stakeholders about unused tables within Snowflake databases. It uses AGGREGATE_ACCESS_HISTORY for comprehensive monitoring and to minimize false positives.

    ## Process Steps:
    1. Check for Table Existence:
       - Ensure the ignore list table exists.
       - SQL Query: CREATE TABLE IF NOT EXISTS GENESIS_BOTS_ALPHA.JANICE_7G8H9J_WORKSPACE.MONITOR_UNUSED_TABLES_IGNORE_LIST (DATABASE_NAME STRING, TABLE_SCHEMA STRING, TABLE_NAME STRING);

    2. Fetch List of Tables:
       - Retrieve a complete list of tables across all databases and schemas, excluding those in the ignore list.
       - SQL Query: SELECT DATABASE_NAME, TABLE_SCHEMA, TABLE_NAME FROM SNOWFLAKE.INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE IN ('BASE TABLE', 'MATERIALIZED VIEW') AND (TABLE_SCHEMA, TABLE_NAME) NOT IN (SELECT TABLE_SCHEMA, TABLE_NAME FROM GENESIS_BOTS_ALPHA.JANICE_7G8H9J_WORKSPACE.MONITOR_UNUSED_TABLES_IGNORE_LIST WHERE DATABASE_NAME = 'GENESIS_BOTS_ALPHA');

    3. Check AGGREGATE_ACCESS_HISTORY:
       - Verify that AGGREGATE_ACCESS_HISTORY is not empty.
       - SQL Query: SELECT COUNT(*) FROM SNOWFLAKE.ACCOUNT_USAGE.AGGREGATE_ACCESS_HISTORY;
       - Action: If count is zero, send an error email indicating the account type is likely not enterprise edition, then exit the process.

    4. Analyze Access Patterns:
       - Determine table usage through access history.
       - SQL Query: WITH AccessedTables AS (SELECT f.value:objectName::string AS TABLE_NAME FROM SNOWFLAKE.ACCOUNT_USAGE.AGGREGATE_ACCESS_HISTORY, TABLE(FLATTEN(INPUT => DIRECT_OBJECTS_ACCESSED)) f WHERE DIRECT_OBJECTS_ACCESSED IS NOT NULL AND INTERVAL_START_TIME > CURRENT_TIMESTAMP - INTERVAL '30 days' GROUP BY TABLE_NAME)

    5. Identify Unused Tables:
       - Compile a list of tables that haven't been accessed within a predefined period.

    6. Optional Notification:
       - Notify relevant stakeholders about the identified unused tables.
       - Prepare content based on results from above queries.

    7. Include Cleanup Suggestions in Email:
       - Provide suggestions for further optimization.
       - Add cleanup suggestions and include a placeholder link for users to access additional analysis.
       - Placeholder Link: <https://app.snowflake.com/genesis_placeholder?bot_id=BOT_ID&thread_id=THREAD_ID>

    ## Example Email Output Structure
    - Subject: Unused Tables Across Snowflake Databases
    - Body: (Example email body structure)
  PROCESS_DETAILS: "Monitor Unused Tables"
  TIMESTAMP: "2000-01-01T00:00:00.000Z"

janice_data_freshness_check_golden:
  BOT_ID: "Janice"
  PROCESS_NAME: "janice_data_freshness_check"
  PROCESS_INSTRUCTIONS: |
    **Process:  Check for data freshness**
    1. **Find tables**
       - Check the processes table for this process and confirm that process_config has data.
       - If process_config does not have any data, inform the user and show the user a list of the names of all of the database tables you have access to.
       - Ask the user which tables they want to use and update the process_config field to reflect these choices.
    2. **Find latest updates in each table with more than the number of rows specified in the parameter table_cutoff_size**
       - Sort each table in the process_config field with more than table_cutoff_size in descending order by latest update date.
    3.  **Find n tables with the oldest dates**
       - Using the first row of each table, find the n tables with the oldest dates where n is a parameter called unfresh_table_count.
    4. **Report back to user**
       - Report the n tables names and update date in ascending order.
  PROCESS_DETAILS: "Data Freshness Check"
  PROCESS_PARAMS: "TABLE_A, TABLE_B, TABLE_C"
  TIMESTAMP: "2000-01-01T00:00:00.000Z"

janice_dangerous_user_report_golden:
  BOT_ID: "janice-7g8h9j"
  PROCESS_INSTRUCTIONS: |
    1. Run the following SQL query to gather data on user roles and privileges:
    ```sql
    (complex SQL query here)
    ```

    2. Analyze the results based on the following criteria:
       - Identify the top 3 users in terms of total privileges granted.
       - Check the distribution of privileges and analyze the granting of the ACCOUNTADMIN role.
       - Report the findings.
  PROCESS_NAME: "Dangerous User Report"
  PROCESS_PARAMS: "TABLE_A, TABLE_B, TABLE_C"
  TIMESTAMP: "2024-09-09 11:43:39.460 -0700"

janice_check_MFA_use_in_snowflake_golden:
  BOT_ID: "janice-7g8h9j"
  PROCESS_INSTRUCTIONS: |
    **Process for Evaluating User MFA and Type Adoption in Snowflake**
    1. **Query to Retrieve User Data**:
       - Run the following SQL query to collect necessary data:
       ```sql
       SELECT NAME, HAS_PASSWORD, EXT_AUTHN_DUO, TYPE
       FROM SNOWFLAKE.ACCOUNT_USAGE.USERS
       WHERE HAS_PASSWORD = TRUE;
       ```

    2. **Analyze MFA Usage**:
       - Calculate the total number of users with passwords set and the number using MFA.
       - Provide recommendations based on MFA adoption rate.
    3. **Analyze User Type Adoption**:
       - Identify `PERSON` type users and check how many have MFA enabled.
    4. **Create Visual Representation**:
       - Create an ASCII art bar chart to visualize MFA and user type adoption.
    5. **Generate Report and Recommendations**:
       - Summarize the findings and provide recommendations.
  PROCESS_NAME: "Check MFA Use in Snowflake"
  PROCESS_PARAMS: "TABLE_A, TABLE_B, TABLE_C"
  TIMESTAMP: "2024-09-09 11:43:39.460 -0700"